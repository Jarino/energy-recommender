{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions with clustered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from prediction import helpers\n",
    "from prediction.predictor import Predictor\n",
    "import utils.data as dutils\n",
    "import utils.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start day\n",
    "START_DAY = datetime(2015,1,1)\n",
    "WINDOW = timedelta(days=14)\n",
    "EVAL_DAYS = 365\n",
    "\n",
    "# get list of all user datasets\n",
    "PATH = '.exports/user_data_joined'\n",
    "USER_PATHS = [os.path.join(PATH, x) for x in os.listdir(PATH)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's setup baseline - simple SVR model evaluated on 10 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \n",
      "\n",
      "MASE:\t1.446697,\t2.239348\n",
      "MSE:\t0.727987,\t0.881286\n",
      "RMSE:\t0.729538,\t0.442449\n",
      "MAE:\t0.501727,\t0.326223\n"
     ]
    }
   ],
   "source": [
    "def baseline():\n",
    "    prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print('Processing user: ', end='')\n",
    "    for index, user_path in enumerate(USER_PATHS[0:10]):\n",
    "        print('%d'%(index+1), end=', ')\n",
    "        data = pd.read_csv(user_path)\n",
    "        \n",
    "        for i in range(0, EVAL_DAYS):\n",
    "            eval_day = START_DAY + timedelta(days=i)\n",
    "            \n",
    "            train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "            test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "            prd.train(train_data)\n",
    "\n",
    "            predicted = prd.predict(test_data)\n",
    "\n",
    "            results.append(prd.eval(predicted, test_data, train_data))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    helpers.print_evaluations(results)\n",
    "            \n",
    "baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignments = pd.read_csv('.exports/clusters/assignments.csv', names=['id','cluster_id'])\n",
    "\n",
    "cluster0_ids = assignments[assignments['cluster_id'] == 0]['id'].tolist()\n",
    "\n",
    "cluster_data = pd.read_csv('.exports/clusters/0.csv', index_col=0)\n",
    "cluster_data.columns = ['year', 'month', 'day', 'spotreba', 'hour']\n",
    "cluster_data = dutils.add_weekdays(cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained and evaluated on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE:\t1.176497,\t0.425597\n",
      "MSE:\t0.142418,\t0.116917\n",
      "RMSE:\t0.353846,\t0.131192\n",
      "MAE:\t0.279319,\t0.108169\n"
     ]
    }
   ],
   "source": [
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(cluster_data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(cluster_data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "        \n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster week average as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t1.392215,\t0.911413\n",
      "MSE:\t4.833897,\t5.243744\n",
      "RMSE:\t1.943702,\t1.027580\n",
      "MAE:\t1.389036,\t0.761725\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "first_year = dutils.select_range(cluster_data, datetime(2014, 1, 1), datetime(2014, 12, 31))\n",
    "week_average = first_year.groupby(['weekday', 'hour']).mean()['spotreba']\n",
    "\n",
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour', 'week_average'], svm.SVR)\n",
    "\n",
    "#userdata = dutils.select_range(pd.read_csv(USER_PATHS[0]), datetime(2014, 1, 1), datetime(2015, 12, 31))\n",
    "\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = pd.read_csv(USER_PATHS[user_index])\n",
    "    \n",
    "    data['week_average'] = 0\n",
    "\n",
    "    for indices, val in week_average.items():\n",
    "        #print(indices, val)\n",
    "        weekday = indices[0]\n",
    "        hour = indices[1]\n",
    "\n",
    "        data.loc[((data['weekday'] == weekday) & (data['hour'] == hour)),'week_average'] = val\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "        \n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster monthly average as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t1.392648,\t0.911868\n",
      "MSE:\t4.836204,\t5.255245\n",
      "RMSE:\t1.944012,\t1.028116\n",
      "MAE:\t1.389413,\t0.762155\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "first_year = dutils.select_range(cluster_data, datetime(2014, 1, 1), datetime(2014, 12, 31))\n",
    "week_average = first_year.groupby(['month', 'weekday', 'hour']).mean()['spotreba']\n",
    "\n",
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour', 'week_average'], svm.SVR)\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = pd.read_csv(USER_PATHS[user_index])\n",
    "    \n",
    "    data['month_average'] = 0\n",
    "\n",
    "    for indices, val in week_average.items():\n",
    "        #print(indices, val)\n",
    "        month = indices[0]\n",
    "        weekday = indices[1]\n",
    "        hour = indices[2]\n",
    "\n",
    "        data.loc[(\n",
    "                (data['month'] == month)\n",
    "                & (data['weekday'] == weekday) \n",
    "                & (data['hour'] == hour)\n",
    "            ),'week_average'] = val\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "        \n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster weekend average as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t1.281207,\t0.950426\n",
      "MSE:\t4.527612,\t5.243757\n",
      "RMSE:\t1.832503,\t1.081456\n",
      "MAE:\t1.275556,\t0.794679\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "first_year = dutils.select_range(cluster_data, datetime(2014, 1, 1), datetime(2014, 12, 31))\n",
    "weekend_average = first_year.groupby(['weekend', 'hour']).mean()['spotreba']\n",
    "\n",
    "prd = Predictor('spotreba', ['weekend', 'hour', 'weekend_average'], svm.SVR)\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = dutils.add_weekdays(pd.read_csv(USER_PATHS[user_index]))\n",
    "    \n",
    "    data['weekend_average'] = 0\n",
    "\n",
    "    for indices, val in weekend_average.items():\n",
    "        #print(indices, val)\n",
    "        weekend = indices[0]\n",
    "        hour = indices[1]\n",
    "\n",
    "        data.loc[(\n",
    "                (data['weekend'] == weekend) \n",
    "                & (data['hour'] == hour)\n",
    "            ),'weekend_average'] = val\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "        \n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on personal data - month, weekday, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t1.371523,\t1.292701\n",
      "MSE:\t2.012039,\t2.778121\n",
      "RMSE:\t1.238078,\t0.692245\n",
      "MAE:\t0.915845,\t0.525045\n"
     ]
    }
   ],
   "source": [
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = pd.read_csv(USER_PATHS[user_index])\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on personal data - weekend, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t1.303226,\t1.297499\n",
      "MSE:\t1.921200,\t2.778209\n",
      "RMSE:\t1.195899,\t0.700732\n",
      "MAE:\t0.866833,\t0.524111\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prd = Predictor('spotreba', ['weekend', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = dutils.add_weekdays(pd.read_csv(USER_PATHS[user_index]))\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on personal data - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t1.507634,\t1.021880\n",
      "MSE:\t2.252021,\t2.652018\n",
      "RMSE:\t1.339654,\t0.676276\n",
      "MAE:\t1.033734,\t0.512194\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prd = Predictor('spotreba', ['month', 'day', 'weekday', 'weekend', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = dutils.add_weekdays(pd.read_csv(USER_PATHS[user_index]))\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t6.345158,\t3.774479\n",
      "MSE:\t4.715070,\t5.024109\n",
      "RMSE:\t1.915637,\t1.022450\n",
      "MAE:\t1.528209,\t0.887734\n"
     ]
    }
   ],
   "source": [
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = pd.read_csv(USER_PATHS[user_index])\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(cluster_data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on mixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \n",
      "\n",
      "MASE:\t2.632462,\t1.502354\n",
      "MSE:\t2.641510,\t3.255659\n",
      "RMSE:\t1.426142,\t0.779505\n",
      "MAE:\t1.072722,\t0.607509\n"
     ]
    }
   ],
   "source": [
    "mixed_data \n",
    "\n",
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster0_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = dutils.select_range(pd.read_csv(USER_PATHS[user_index]), datetime(2014, 1, 1), datetime(2015,12,31))\n",
    "\n",
    "    mixed_data = cluster_data.copy()\n",
    "    mixed_data['spotreba'] = np.c_[cluster_data['spotreba'].as_matrix(), data['spotreba']].mean(axis=1)\n",
    "\n",
    "    \n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "        \n",
    "        train_data = dutils.select_range(mixed_data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster1_ids = assignments[assignments['cluster_id'] == 1]['id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on personal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_paths = np.array(USER_PATHS)[cluster1_ids].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, MASE:\t1.305228,\t1.057415\n",
      "MSE:\t0.997915,\t1.245958\n",
      "RMSE:\t0.876413,\t0.479391\n",
      "MAE:\t0.608321,\t0.342043\n"
     ]
    }
   ],
   "source": [
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_path in enumerate(data_paths):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = pd.read_csv(user_path)\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "        \n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on cluster average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, \n",
      "\n",
      "MASE:\t3.177730,\t1.477857\n",
      "MSE:\t1.217662,\t1.478113\n",
      "RMSE:\t0.991021,\t0.485325\n",
      "MAE:\t0.753836,\t0.358887\n"
     ]
    }
   ],
   "source": [
    "cluster_data = pd.read_csv('.exports/clusters/1.csv', index_col=0)\n",
    "cluster_data.columns = ['year', 'month', 'day', 'spotreba', 'hour']\n",
    "cluster_data = dutils.add_weekdays(cluster_data)\n",
    "\n",
    "prd = Predictor('spotreba', ['month', 'weekday', 'hour'], svm.SVR)\n",
    "\n",
    "results = []\n",
    "\n",
    "print('Processing user: ', end='')\n",
    "for index, user_index in enumerate(cluster1_ids):\n",
    "    print('%d'%(index+1), end=', ')\n",
    "    data = pd.read_csv(USER_PATHS[user_index])\n",
    "\n",
    "    for i in range(0, EVAL_DAYS):\n",
    "        eval_day = START_DAY + timedelta(days=i)\n",
    "\n",
    "        train_data = dutils.select_range(cluster_data, eval_day - WINDOW - timedelta(days=1), eval_day - timedelta(days=1))\n",
    "        test_data = dutils.select_range(data, eval_day, eval_day)\n",
    "\n",
    "        prd.train(train_data)\n",
    "\n",
    "        predicted = prd.predict(test_data)\n",
    "\n",
    "        results.append(prd.eval(predicted, test_data, train_data))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "helpers.print_evaluations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
